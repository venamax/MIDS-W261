{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W261 Final Exame\n",
    "Student: Kuan lin<br/>kuanlin@ischool.berkeley.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ET10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-1.4142505069117979, pvalue=0.15728991985619109)\n",
      "p_val_onetailed: 0.0786449599281\n",
      "p_val_onetailed: 0.142517435046\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "sample1 = [0.5, 0.5, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0] + [0]*(100000-9)\n",
    "sample2 = [1.5, 0.5, 0.0, 3.0, 4.0] + [0]*(100000-5)\n",
    "t_result = stats.ttest_ind(sample2,sample1)\n",
    "print t_result\n",
    "p_val_two_tailed = t_result[1]\n",
    "print \"p_val_onetailed: %s\"%(p_val_two_tailed/2) # 0.0786 insignificant\n",
    "\n",
    "sample1 = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] + [0]*(100000-9)\n",
    "sample2 = [1.0, 1.0, 1.0, 1.0, 1.0] + [0]*(100000-5)\n",
    "p_val_two_tailed = stats.ttest_ind(sample2,sample1)[1]\n",
    "print \"p_val_onetailed: %s\"%(p_val_two_tailed/2) # 0.142 insignificant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ET 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 1.6.1\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.11 (default, Feb 16 2016 09:58:36)\n",
      "SparkContext available as sc, HiveContext available as sqlContext.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "#spark_home = os.environ['SPARK_HOME'] = '/Users/liang/Downloads/spark-1.4.1-bin-hadoop2.6/'\n",
    "spark_home = os.environ['SPARK_HOME'] = 'D:\\\\spark-1.6.1-bin-hadoop2.6'\n",
    "\n",
    "if not spark_home:\n",
    "    raise ValueError('SPARK_HOME enviroment variable is not set')\n",
    "sys.path.insert(0,os.path.join(spark_home,'python'))\n",
    "sys.path.insert(0,os.path.join(spark_home,'python', 'lib', 'py4j-0.9-src.zip'))\n",
    "execfile(os.path.join(spark_home,'python', 'pyspark', 'shell.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, (4, 9)), (3, (4, 6)), (3, (6, 9)), (3, (6, 6))]\n"
     ]
    }
   ],
   "source": [
    "RDD1 = sc.parallelize([(1, 2), (3, 4), (3, 6)])\n",
    "RDD2 = sc.parallelize([(3, 9), (3, 6)])\n",
    "print RDD1.join(RDD2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ET15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing beerSales.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile beerSales.txt\n",
    "Week\tPRICE12PK\tPRICE18PK\tPRICE30PK\tCASES12PK\tCASES18PK\tCASES30PK\n",
    "1\t19.98\t14.10\t15.19\t223.5\t439\t55.00\n",
    "2\t19.98\t18.65\t15.19\t215.0\t98\t66.75\n",
    "3\t19.98\t18.65\t13.87\t227.5\t70\t242.00\n",
    "4\t19.98\t18.65\t12.83\t244.5\t52\t488.50\n",
    "5\t19.98\t18.65\t13.16\t313.5\t64\t308.75\n",
    "6\t19.98\t18.65\t15.19\t279.0\t72\t111.75\n",
    "7\t19.98\t18.65\t13.92\t238.0\t47\t252.50\n",
    "8\t20.10\t18.73\t14.42\t315.5\t85\t221.25\n",
    "9\t20.12\t18.75\t13.83\t217.0\t59\t245.25\n",
    "10\t20.13\t18.75\t14.50\t209.5\t63\t148.50\n",
    "11\t20.14\t18.75\t13.87\t227.0\t57\t229.75\n",
    "12\t20.12\t18.75\t13.64\t216.5\t54\t312.00\n",
    "13\t20.12\t13.87\t14.31\t169.0\t404\t96.75\n",
    "14\t20.13\t14.27\t13.85\t178.0\t380\t123.25\n",
    "15\t20.14\t18.76\t14.20\t301.5\t65\t200.50\n",
    "16\t20.14\t18.77\t13.64\t266.5\t40\t359.75\n",
    "17\t20.13\t13.87\t14.33\t182.5\t456\t113.50\n",
    "18\t20.13\t14.14\t13.14\t159.0\t176\t136.50\n",
    "19\t20.13\t18.76\t13.81\t285.5\t61\t225.50\n",
    "20\t20.13\t18.72\t15.19\t360.0\t91\t122.25\n",
    "21\t20.13\t18.76\t13.13\t263.0\t59\t443.75\n",
    "22\t19.18\t18.76\t13.63\t443.5\t83\t322.75\n",
    "23\t14.78\t18.74\t15.19\t1101.5\t41\t53.00\n",
    "24\t16.04\t18.75\t13.89\t814.0\t47\t140.75\n",
    "25\t20.12\t18.75\t14.28\t365.0\t84\t210.75\n",
    "26\t19.75\t18.75\t15.19\t510.0\t85\t110.50\n",
    "27\t19.65\t18.75\t13.12\t580.5\t116\t568.25\n",
    "28\t19.69\t13.79\t13.78\t251.0\t544\t115.50\n",
    "29\t20.12\t13.49\t15.19\t237.0\t890\t58.75\n",
    "30\t20.12\t14.89\t15.19\t302.5\t371\t77.25\n",
    "31\t20.13\t13.94\t15.19\t229.5\t557\t66.25\n",
    "32\t20.14\t13.67\t15.19\t188.5\t775\t50.00\n",
    "33\t15.14\t14.43\t15.19\t795.5\t236\t46.50\n",
    "34\t14.33\t18.75\t15.19\t1556.5\t43\t65.75\n",
    "35\t16.24\t18.22\t13.14\t807.5\t63\t252.75\n",
    "36\t19.93\t14.06\t13.45\t243.0\t469\t179.00\n",
    "37\t21.06\t14.43\t13.00\t201.5\t335\t226.25\n",
    "38\t21.19\t19.48\t13.60\t294.0\t75\t288.50\n",
    "39\t21.23\t15.15\t14.46\t220.5\t461\t114.25\n",
    "40\t20.12\t13.79\t14.94\t255.5\t817\t70.00\n",
    "41\t14.73\t14.31\t15.19\t920.5\t200\t47.75\n",
    "42\t14.57\t19.50\t15.19\t730.0\t32\t98.75\n",
    "43\t15.94\t13.85\t15.19\t262.5\t460\t77.00\n",
    "44\t20.70\t14.23\t13.43\t209.5\t751\t160.50\n",
    "45\t19.57\t19.31\t14.37\t283.0\t70\t143.50\n",
    "46\t19.60\t19.29\t15.19\t262.5\t80\t133.00\n",
    "47\t19.94\t13.76\t15.19\t310.0\t523\t68.75\n",
    "48\t21.28\t13.45\t15.19\t278.5\t741\t81.75\n",
    "49\t14.56\t15.13\t15.19\t741.5\t130\t56.25\n",
    "50\t14.39\t19.43\t15.19\t1316.0\t69\t68.75\n",
    "51\t16.81\t13.26\t15.19\t449.0\t493\t49.25\n",
    "52\t19.86\t13.92\t15.19\t505.0\t814\t76.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[439.0, 98.0, 70.0, 52.0, 64.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.textFile('beerSales.txt')\n",
    "#data.take(1)\n",
    "cases18pk_data = data.filter(lambda line: not line.startswith(\"Week\")).map(lambda line: float(line.split('\\t')[5])).cache()\n",
    "cases18pk_data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mean model\n",
    "cases18pk_mean = cases18pk_data.reduce(lambda a,b: a+b)/cases18pk_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200.44422333\n"
     ]
    }
   ],
   "source": [
    "#print cases18pk_mean\n",
    "MAPE = cases18pk_data.filter(lambda x: x!= 0).map(lambda x: 100.0*abs(x-cases18pk_mean)/x).reduce(lambda a,b: a+b)/cases18pk_data.filter(lambda x: x!= 0).count()\n",
    "print MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ET16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.5849342896\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "cases18pk_log_data = cases18pk_data.map(lambda x: math.log(x)).cache()\n",
    "cases18pk_log_mean = cases18pk_log_data.reduce(lambda a,b: a+b)/cases18pk_data.count()\n",
    "MAPE_logged = cases18pk_log_data.map(lambda x: 100.0*abs(x-cases18pk_log_mean)/x).reduce(lambda a,b: a+b)/cases18pk_log_data.count()\n",
    "\n",
    "print MAPE_logged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ET17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint, LinearRegressionWithSGD, LinearRegressionModel\n",
    "import math\n",
    "def parsePoint(line):\n",
    "    values = map(float, line.split('\\t'))\n",
    "    log_case18pk = math.log(values[5])\n",
    "    log_price12pk = math.log(values[1])\n",
    "    log_price18pk = math.log(values[2])\n",
    "    log_price30pk = math.log(values[3])\n",
    "    return LabeledPoint(log_case18pk, [log_price12pk, log_price18pk, log_price30pk])\n",
    "\n",
    "regression_data = data.filter(lambda line: not line.startswith(\"Week\")).map(parsePoint).cache()\n",
    "#print regression_data.collect()\n",
    "#print regression_data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LinearRegressionWithSGD.train(regression_data, iterations=50, step=0.00000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.9999579406\n"
     ]
    }
   ],
   "source": [
    "valuesAndPreds = regression_data.map(lambda p: (p.label, model.predict(p.features)))\n",
    "#print valuesAndPreds.take(5)\n",
    "MAPE = valuesAndPreds.map(lambda (label,pred): 100.0*abs(label-pred)/label).reduce(lambda a,b:a+b)/regression_data.count()\n",
    "print MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Re-try with Other Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.2038623593\n",
      "weights:\n",
      "[2.02179230116e-07,1.89853159299e-07,1.82853796073e-07]\n"
     ]
    }
   ],
   "source": [
    "model2 = LinearRegressionWithSGD.train(regression_data, iterations=50, step=0.00000001, intercept=True, convergenceTol=0.00001)\n",
    "valuesAndPreds = regression_data.map(lambda p: (p.label, model2.predict(p.features)))\n",
    "#print valuesAndPreds.take(5)\n",
    "MAPE = valuesAndPreds.map(lambda (label,pred): 100.0*abs(label-pred)/label).reduce(lambda a,b:a+b)/regression_data.count()\n",
    "print MAPE\n",
    "print \"weights:\"\n",
    "print model2.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "labels = []\n",
    "features = []\n",
    "for line in open('beerSales.txt', 'r'):\n",
    "    if line.startswith(\"Week\"): continue\n",
    "    values = map(float, line.split('\\t'))\n",
    "    log_case18pk = math.log(values[5])\n",
    "    log_price12pk = math.log(values[1])\n",
    "    log_price18pk = math.log(values[2])\n",
    "    log_price30pk = math.log(values[3])\n",
    "    labels.append(log_case18pk)\n",
    "    features.append([log_price12pk, log_price18pk, log_price30pk])\n",
    "\n",
    "model3 = LinearRegression(fit_intercept=True, normalize=False)\n",
    "model3.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: [ 2.01637714 -6.33092326  2.47016635]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.2150866635659492"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_results = model3.predict(features)\n",
    "print \"weights: %s\"%str(model3.coef_)\n",
    "sum(map(lambda (label,pred): 100.0*abs(label-pred)/label,[(label,pred) for (label,pred) in zip(labels, fitted_results)]))/len(fitted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
